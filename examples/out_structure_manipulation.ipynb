{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from gavlib.io import import_out_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../../projects/dstrf/data/out_structures/out_HG_LIJ113_holm.mat'\n",
    "out = import_out_struct(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "['name', 'sound', 'soundf', 'dataf', 'duration', 'befaft', 'type', 'resp', 'artifact', 'trial', 'ti', 'label', 'reverb', 'prelabel', 'significant_elecs_from_bahars']\n",
      "[(30, 6197), (30, 5203), (30, 6430), (30, 6206), (30, 6560), (30, 7194), (30, 8540), (30, 6586), (30, 5904), (30, 5621), (30, 8707), (30, 7602), (30, 4977), (30, 3751), (30, 3485), (30, 3778), (30, 2979), (30, 2986), (30, 448)]\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the data we have\n",
    "print(len(out)) # number of trials/stimuli recorded\n",
    "print(out.fields) # number of fields for each trial\n",
    "print([tmp.shape for tmp in out.get_field('resp')]) # shape of each trial: (num_elecs * time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's normalize the response data over time (and across all trials)\n",
    "from gavlib.preprocessing import normalize\n",
    "\n",
    "out_norm = normalize(out, field='resp', axis=-1, method='zscore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82153982 1.13056419 1.46729383 1.63991529 1.80746745 1.6620427\n",
      " 1.49965842 1.54505928 1.47529691 1.35430757 1.23219641 1.25273965\n",
      " 1.30835683 0.95506827 0.82565716 0.74135743 0.8675098  1.09265345\n",
      " 1.18879407 1.26099978 1.24296696 1.20067893 1.51760834 1.74466428\n",
      " 1.94255046 1.80243959 1.20675949 0.88059825 0.90514038 1.09985971]\n",
      "[0.82046506 0.96945641 1.07992902 1.11316762 1.11249377 1.07419394\n",
      " 1.02577959 1.06583431 1.11442683 1.12698377 1.08298257 1.08600933\n",
      " 1.07794006 0.92745478 0.91390538 0.86545181 0.95008439 1.03271206\n",
      " 1.03436409 1.00737443 1.045131   1.03296959 1.13533031 1.12382104\n",
      " 1.15945381 1.1279667  1.05699912 0.97674993 0.97234702 1.01658648]\n"
     ]
    }
   ],
   "source": [
    "# print out the standard deviation before and after normalization\n",
    "# Note: the standard dev. is not exactly 1 because it was computed over the full out struct,\n",
    "# not for each trial individually\n",
    "\n",
    "print(out[0]['resp'].std(axis=-1))\n",
    "print(out_norm[0]['resp'].std(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dstrf",
   "language": "python",
   "name": "dstrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
